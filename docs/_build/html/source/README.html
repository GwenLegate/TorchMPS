
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>TorchMPS: Matrix Product States in Pytorch &#8212; TorchMPS 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Welcome to TorchMPS’s documentation!" href="../index.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../index.html" title="Welcome to TorchMPS’s documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">TorchMPS 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">TorchMPS: Matrix Product States in Pytorch</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="torchmps-matrix-product-states-in-pytorch">
<h1>TorchMPS: Matrix Product States in Pytorch<a class="headerlink" href="#torchmps-matrix-product-states-in-pytorch" title="Permalink to this headline">¶</a></h1>
<p>TorchMPS is a framework for working with matrix product state (also known as MPS or tensor train) models within Pytorch. Our MPS models are written as Pytorch Modules, and can simply be viewed as differentiable black boxes that are interchangeable with standard neural network layers. However, the rich structure of MPS’s allows for more interesting behavior, such as:</p>
<ul class="simple">
<li><p>A novel adaptive training algorithm (inspired by <a class="reference external" href="https://arxiv.org/abs/1605.05775">Stoudenmire and Schwab 2016</a>), which dynamically varies the MPS hyperparameters (MPS bond dimensions) during the course of training.</p></li>
<li><p>Mechanisms for controlling MPS geometry, such as custom “routing” of the MPS through different regions of the input data, or periodic boundary conditions that give the MPS a circular topology.</p></li>
<li><p>Choice of tensor contraction strategies, which represent flexible tradeoffs between computational cost and parallelizability of the computation graph.</p></li>
</ul>
<div class="section" id="what-our-mps-models-do">
<h2>What our MPS Models Do<a class="headerlink" href="#what-our-mps-models-do" title="Permalink to this headline">¶</a></h2>
<p>The function computed by our MPS Module comes from embedding input data in a high-dimensional feature space before contracting it with an MPS in the same space, as described in <a class="reference external" href="https://arxiv.org/abs/1605.03795">Novikov, Trofimov, and Oseledets 2016</a> and <a class="reference external" href="https://arxiv.org/abs/1605.05775">Stoudenmire and Schwab 2016</a>. For scalar outputs, this contraction step is formally identical to linear regression, but the (exponentially) large feature space and MPS-parameterized weight vector makes the overall function significantly more expressive. In general, the output is associated with a single site of the MPS, whose placement within the network is a hyperparameter that varies the inductive bias towards different regions of the input data.</p>
</div>
<div class="section" id="how-to-use-torchmps">
<h2>How to Use TorchMPS<a class="headerlink" href="#how-to-use-torchmps" title="Permalink to this headline">¶</a></h2>
<p>As our models are built on Pytorch, users will need to have this installed in a directory contained in the environment variable <code class="docutils literal notranslate"><span class="pre">PYTHONPATH</span></code>. Torchvision is also used in our example script <code class="docutils literal notranslate"><span class="pre">train_script.py</span></code>, but not anywhere else.</p>
<p>After cloning the repo, running <code class="docutils literal notranslate"><span class="pre">train_script.py</span></code> gives a simple example of how our MPS can be used to classify MNIST digits. In general, MPS models can be invoked by simply importing the class <code class="docutils literal notranslate"><span class="pre">MPS</span></code> from <code class="docutils literal notranslate"><span class="pre">torchmps.py</span></code>, and then creating a new <code class="docutils literal notranslate"><span class="pre">MPS</span></code> instance. For example, an MPS which classifies 32x32 images into one of 10 categories can be defined and used as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchmps.py</span> <span class="kn">import</span> <span class="n">MPS</span>

<span class="n">my_mps</span> <span class="o">=</span> <span class="n">MPS</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">32</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bond_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="c1"># Now get a batch of (flattened) images to classify...</span>

<span class="n">batch_scores</span> <span class="o">=</span> <span class="n">my_mps</span><span class="p">(</span><span class="n">batch_images</span><span class="p">)</span>
</pre></div>
</div>
<p>That’s it! After creation, <code class="docutils literal notranslate"><span class="pre">my_mps</span></code> acts as a stateful function whose internal parameters can be trained exactly as any other Pytorch Module (e.g. nn.Linear, nn.Conv1d, nn.Sequential, etc).</p>
<p>The possible arguments for defining an MPS are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_dim</span></code>: The dimension of the input we feed to our MPS</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output_dim</span></code>: The dimension of the output we get from each input</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bond_dim</span></code>: The internal bond dimension, a hyperparameter that sets the expressivity of our MPS. When in adaptive training mode, <code class="docutils literal notranslate"><span class="pre">bond_dim</span></code> instead sets the <strong>maximum</strong> possible bond dimension, with the initial bond dimension equal to <code class="docutils literal notranslate"><span class="pre">output_dim</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">feature_dim</span></code>: The dimension of the local feature spaces we embed each datum in (<em>default = 2</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">adaptive_mode</span></code>: Whether our MPS is trained with its bond dimensions chosen adaptively or are fixed at creation (<em>default = False (fixed bonds)</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">periodic_bc</span></code>: Whether our MPS has periodic boundary conditions (making it a tensor ring) or open boundary conditions (<em>default = False (open boundaries)</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">parallel_eval</span></code>: For open boundary conditions, whether contraction of tensors is performed serially or in parallel (<em>default = False (serial)</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">label_site</span></code>: The location in the MPS chain where our output lives after contracting all other sites with inputs (_default = input<em>dim // 2</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: A list specifying the path our MPS takes through the input data. For example, <code class="docutils literal notranslate"><span class="pre">path</span> <span class="pre">=</span> <span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">...,</span> <span class="pre">input_dim-1]</span></code> gives the standard in-order traversal (used if <code class="docutils literal notranslate"><span class="pre">path</span> <span class="pre">=</span> <span class="pre">None</span></code>), while <code class="docutils literal notranslate"><span class="pre">path</span> <span class="pre">=</span> <span class="pre">[0,</span> <span class="pre">2,</span> <span class="pre">...,</span> <span class="pre">input_dim-1]</span></code> defines an MPS which only acts on even-valued sites within our input (<em>default = None</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cutoff</span></code>: The singular value cutoff which controls adaptation of bond dimensions (<em>default = 1e-9</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">merge_threshold</span></code>: The number of inputs before our MPS dynamically shifts its merge state, which updates half the bond dimensions at a time (<em>default = 2000, only used in adaptive mode</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init_std</span></code>: The size of the random terms used during initialization (<em>default = 1e-9</em>)</p></li>
</ul>
<p>To define a custom feature map for embedding input data, first define a function <code class="docutils literal notranslate"><span class="pre">feature_map</span></code> which acts on a single scalar input and outputs a Pytorch vector of size <code class="docutils literal notranslate"><span class="pre">feature_dim</span></code>. After initializing an MPS <code class="docutils literal notranslate"><span class="pre">my_mps</span></code>, simply call <code class="docutils literal notranslate"><span class="pre">my_mps.register_feature_map(feature_map)</span></code>, and the user-specified <code class="docutils literal notranslate"><span class="pre">feature_map</span></code> will be applied to all input data given to <code class="docutils literal notranslate"><span class="pre">my_mps</span></code>. If <code class="docutils literal notranslate"><span class="pre">feature_map</span></code> is also a Pytorch Module, then any parameters associated with the map will be included in <code class="docutils literal notranslate"><span class="pre">my_mps.parameters()</span></code>. This streamlines the use of trainable feature maps within an MPS model.</p>
</div>
<div class="section" id="adaptive-training-using-distributed-dmrg">
<h2>Adaptive Training using Distributed DMRG<a class="headerlink" href="#adaptive-training-using-distributed-dmrg" title="Permalink to this headline">¶</a></h2>
<p>When an MPS is initialized with <code class="docutils literal notranslate"><span class="pre">adaptive_mode</span></code> set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, training proceeds by alternating between different “offsets” of the MPS cores. Each offset combines adjacent pairs of cores into effective merged cores, so that half of the bonds in the MPS are contracted over. This contraction provides a low rank decomposition of the initial merged core, but as training progresses the rank across this bond will typically increase.</p>
<p>After a certain number of inputs are fed to the MPS (equal to <code class="docutils literal notranslate"><span class="pre">merge_threshold</span></code>), each merged core is split in two via a singular value decomposition (SVD) across the contracted bond index. A truncation is then applied which removes all singular values less than <code class="docutils literal notranslate"><span class="pre">cutoff</span></code>, yielding a collection of split cores with half of the bonds having reduced bond dimension. These cores are then merged along a different offset and the process repeated, so that all of the bond dimensions are eventually optimized.</p>
<p>Throughout this process, real-time lists of all the truncated bond dimensions and singular value spectra are accessible as the attributes <code class="docutils literal notranslate"><span class="pre">my_mps.bond_list</span></code> and <code class="docutils literal notranslate"><span class="pre">my_mps.sv_list</span></code>.</p>
<p>This adaptive training mode was directly inspired by the ML DMRG training procedure in <a class="reference external" href="https://arxiv.org/abs/1605.05775">Stoudenmire and Schwab 2016</a>, which uses a similar division of training into merging and splitting steps, but with a different overall control flow.</p>
</div>
<div class="section" id="similar-software">
<h2>Similar Software<a class="headerlink" href="#similar-software" title="Permalink to this headline">¶</a></h2>
<p>There are plenty of excellent software packages for manipulating matrix product states/tensor trains, some notable ones including the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/google/TensorNetwork">TensorNetwork</a> (Python, TensorFlow): Powerful library for defining and manipulating general tensor network models, which is described in <a class="reference external" href="https://arxiv.org/abs/1905.01330">Roberts et al. 2019</a>.</p></li>
<li><p><a class="reference external" href="https://github.com/Bihaqo/t3f">T3F</a> (Python, TensorFlow): Useful for general tensor train applications, T3F includes lots of support for working with tensor train factorizations of matrices (as used in <a class="reference external" href="https://arxiv.org/abs/1509.06569">Novikov et al. 2015</a>), and supports Riemannian optimization techniques for improved training.</p></li>
<li><p><a class="reference external" href="https://github.com/rballester/tntorch">tntorch</a> (Python, Pytorch): Implements many different tensor factorizations, including CP, Tucker, and tensor train.</p></li>
<li><p><a class="reference external" href="https://github.com/emstoudenmire/TNML">TNML</a> (C++, ITensor): Implements the DMRG-style training described in <a class="reference external" href="https://arxiv.org/abs/1605.05775">Stoudenmire and Schwab 2016</a>, which had a major influence on our adaptive training algorithm.</p></li>
</ul>
<p>A defining quality of our library is the emphasis on using matrix product states as functional modules which can be easily interchanged with existing neural network components, while still allowing for interesting MPS-specific features.</p>
</div>
<div class="section" id="citing-torchmps">
<h2>Citing TorchMPS<a class="headerlink" href="#citing-torchmps" title="Permalink to this headline">¶</a></h2>
<p>If you found TorchMPS useful for your work, you can cite it by adding the following entry to your BibTeX bibliography (<code class="docutils literal notranslate"><span class="pre">.bib</span></code>) file:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span><span class="nl">torchmps</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Miller, Jacob}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TorchMPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{GitHub}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{GitHub repository}</span><span class="p">,</span>
  <span class="na">howpublished</span> <span class="p">=</span> <span class="s">{\url{https://github.com/jemisjoky/torchmps}}</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">TorchMPS: Matrix Product States in Pytorch</a><ul>
<li><a class="reference internal" href="#what-our-mps-models-do">What our MPS Models Do</a></li>
<li><a class="reference internal" href="#how-to-use-torchmps">How to Use TorchMPS</a></li>
<li><a class="reference internal" href="#adaptive-training-using-distributed-dmrg">Adaptive Training using Distributed DMRG</a></li>
<li><a class="reference internal" href="#similar-software">Similar Software</a></li>
<li><a class="reference internal" href="#citing-torchmps">Citing TorchMPS</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../index.html"
                        title="previous chapter">Welcome to TorchMPS’s documentation!</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/source/README.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../index.html" title="Welcome to TorchMPS’s documentation!"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">TorchMPS 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">TorchMPS: Matrix Product States in Pytorch</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, Jacob Miller.
    </div>
  </body>
</html>